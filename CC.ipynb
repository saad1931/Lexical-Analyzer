{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb37266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Set of reserved words\n",
    "RESERVED_WORDS = ['if', 'else', 'while', 'for', 'foreach', 'return']\n",
    "\n",
    "# Set of token names\n",
    "TOKEN_NAMES = ['ID', 'NUMBER', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'ASSIGN', 'LPAREN', 'RPAREN', 'LBRACKET', 'RBRACKET', 'LBRACE', 'RBRACE', 'LT', 'LE', 'GT', 'GE', 'EQ', 'NE'] + RESERVED_WORDS\n",
    "\n",
    "def get_tokens(text):\n",
    "    # Splitting the text into lines\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Initialize the list of tokens\n",
    "    tokens = []\n",
    "\n",
    "    # Regular expressions for each token type\n",
    "    token_regexes = {\n",
    "        'ID': r'[a-zA-Z_][a-zA-Z0-9_]*',\n",
    "        'NUMBER': r'\\d+(\\.\\d+)?',\n",
    "        'PLUS': r'\\+',\n",
    "        'MINUS': r'-',\n",
    "        'TIMES': r'\\*',\n",
    "        'DIVIDE': r'/',\n",
    "        'ASSIGN': r'=',\n",
    "        'LPAREN': r'\\(',\n",
    "        'RPAREN': r'\\)',\n",
    "        'LBRACKET': r'\\[',\n",
    "        'RBRACKET': r'\\]',\n",
    "        'LBRACE': r'\\{',\n",
    "        'RBRACE': r'\\}',\n",
    "        'LT': r'<',\n",
    "        'LE': r'<=',\n",
    "        'GT': r'>',\n",
    "        'GE': r'>=',\n",
    "        'EQ': r'==',\n",
    "        'NE': r'!=',\n",
    "        'SE': r';',\n",
    "        'SP': r' ',\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Compiling the regular expressions\n",
    "    token_patterns = [ (name, re.compile(regex)) for name, regex in token_regexes.items() ]\n",
    "\n",
    "    # Line and character position\n",
    "    line_num = 1\n",
    "    pos = 0\n",
    "\n",
    "    # Iterate through each line of the text\n",
    "    for line in lines:\n",
    "        # While the line has characters\n",
    "        while pos < len(line):\n",
    "            # Iterate through the token patterns\n",
    "            for name, pattern in token_patterns:\n",
    "                # Check if the pattern matches\n",
    "                match = pattern.match(line, pos)\n",
    "                if match:\n",
    "                    # Extract the token value\n",
    "                    value = match.group()\n",
    "                    # Check if the token is a reserved word\n",
    "                    if name in RESERVED_WORDS:\n",
    "                        tokens.append((name, value))\n",
    "                    else:\n",
    "                        tokens.append((name, value))\n",
    "                    # Update the character position\n",
    "                    pos = match.end()\n",
    "                    break\n",
    "            else:\n",
    "                # If no pattern matches, it's an error\n",
    "                raise Exception('Invalid character at line {0}, character {1}'.format(line_num, pos))\n",
    "        # Update the line number and reset the character position\n",
    "        line_num += 1\n",
    "        pos = 0\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2470f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ID', 'foreach')\n",
      "('SP', ' ')\n",
      "('LPAREN', '(')\n",
      "('ID', 'int')\n",
      "('SP', ' ')\n",
      "('ID', 'i')\n",
      "('SP', ' ')\n",
      "('ID', 'in')\n",
      "('SP', ' ')\n",
      "('ID', 'list')\n",
      "('RPAREN', ')')\n",
      "('SP', ' ')\n",
      "('LBRACE', '{')\n",
      "('SP', ' ')\n",
      "('SP', ' ')\n",
      "('ID', 'if')\n",
      "('SP', ' ')\n",
      "('LPAREN', '(')\n",
      "('ID', 'i')\n",
      "('SP', ' ')\n",
      "('GT', '>')\n",
      "('SP', ' ')\n",
      "('NUMBER', '0')\n",
      "('RPAREN', ')')\n",
      "('SP', ' ')\n",
      "('LBRACE', '{')\n",
      "('SP', ' ')\n",
      "('SP', ' ')\n",
      "('SP', ' ')\n",
      "('SP', ' ')\n",
      "('ID', 'sum')\n",
      "('SP', ' ')\n",
      "('PLUS', '+')\n",
      "('ASSIGN', '=')\n",
      "('SP', ' ')\n",
      "('ID', 'i')\n",
      "('SE', ';')\n",
      "('SP', ' ')\n",
      "('SP', ' ')\n",
      "('RBRACE', '}')\n",
      "('RBRACE', '}')\n"
     ]
    }
   ],
   "source": [
    "# Read in the text file\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Get the list of tokens\n",
    "tokens = get_tokens(text)\n",
    "\n",
    "# Print the tokens\n",
    "for token in tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce53550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
